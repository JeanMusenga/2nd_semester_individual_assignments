{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMRvU/JSo2WEKCoRixGIjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanMusenga/PhD-Thesis_2024_Musenga/blob/main/feature_extraction_from_Ruiyin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Agbbu-OS4kY"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import normalize\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import fasttext\n",
        "from preprocessing.w2vemb import EMB\n",
        "from preprocessing.managedb import ManageDB\n",
        "from preprocessing.preprocessing import preprocess\n",
        "\n",
        "# load SO_w2v_200\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"D:\\data\\word_embedding\\SO_vectors_200.bin\", binary=True)\n",
        "# load FastText_200\n",
        "fasttext.FastText.eprint = lambda x: None\n",
        "# ft = fasttext.load_model('D:\\data\\word_embedding\\cc.en.200.bin')\n",
        "# ft = fasttext.load_model('D:\\data\\word_embedding\\cc.en.100.bin')\n",
        "# ft = fasttext.load_model('D:\\data\\word_embedding\\cc.en.300.bin')\n",
        "\n",
        "# load GloVe_200\n",
        "# gensim_file = 'D:\\data\\word_embedding\\glove.twitter.27B.200d.txt'\n",
        "# md = ManageDB()\n",
        "# md.add_file2db('glove.twitter.27B.200d', gensim_file, 200, 1193513)\n",
        "# GloVe = EMB(name='glove.twitter.27B.200d', dimensions=200)\n",
        "\n",
        "read_path1 = r'D:\\data\\Violation symptoms.xlsx'\n",
        "data1 = pd.read_excel(read_path1, sheet_name='combination', na_values='n/a')\n",
        "violation_comment = data1['Comment'].tolist()\n",
        "\n",
        "read_path2 = r'D:\\data\\Randomly_selected_comments.xlsx'\n",
        "data2 = pd.read_excel(read_path2, sheet_name='Comments', na_values='n/a')\n",
        "non_violation_comment = data2['Comment'].tolist()\n",
        "\n",
        "word2id = wv_from_bin.key_to_index  # dict: {word, index}; example: {'a': 0, 'b', 1, ...}\n",
        "# ft_word_dic = ft.words\n",
        "\n",
        "'''Feature Extraction'''\n",
        "def get_word_vectors(embeding_model, word):\n",
        "    if embeding_model == 'SO_w2v':\n",
        "        if word == '0':\n",
        "            word = '<UNK>'  # replace '0'\n",
        "        if word in word2id:\n",
        "            vector = wv_from_bin.get_vector(word)\n",
        "        else:\n",
        "            vector = np.array([0.] * 200, dtype=np.float64)\n",
        "\n",
        "    if embeding_model == 'FastText':\n",
        "        if word == '0':\n",
        "            word = '<UNK>'\n",
        "        if word in ft_word_dic:\n",
        "            vector = ft.get_word_vector(word)\n",
        "        else:\n",
        "            vector = np.array([0.] * 300, dtype=np.float64)     # adjust the dimension\n",
        "\n",
        "    if embeding_model == 'GloVe':\n",
        "        if word == '0':\n",
        "            word = '<UNK>'\n",
        "        if word in GloVe:\n",
        "            vector = np.array(GloVe.get_vector(word))\n",
        "        else:\n",
        "            vector = np.array([0.] * 200, dtype=np.float64)\n",
        "    return vector\n",
        "\n",
        "def get_sen_vectors(embeding_model, sentence):   # list; example: ['this', 'line', 'violat', 'new', 'hack', 'rule']\n",
        "    # sentence_vec = np.array([0.] * 200, dtype=np.float64)\n",
        "    sentence_vec = np.array([0.] * 300, dtype=np.float64)\n",
        "    for word in sentence:\n",
        "        sentence_vec += get_word_vectors(embeding_model, word)\n",
        "    return sentence_vec  # return: <class 'numpy.ndarray'>\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    '''Manually choose the feature extraction method (i.e., SO_w2v, FastText, GloVe)'''\n",
        "    preprocessed_comment = []\n",
        "    for item in violation_comment:\n",
        "        # preprocessed_comment.append(get_sen_vectors('SO_w2v_200', preprocess(item)))\n",
        "        preprocessed_comment.append(get_sen_vectors('FastText', preprocess(item)))\n",
        "        # preprocessed_comment.append(get_sen_vectors('GloVe_200', preprocess(item)))\n",
        "    Preprocessed_Data = pd.DataFrame(preprocessed_comment)\n",
        "\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\SO_w2v_200_violation.csv', index=False)   # SO_w2v_200\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_200_violation.csv', index=False)\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_100_violation.csv', index=False)\n",
        "    Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_300_violation.csv', index=False)\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\GloVe_200_violation.csv', index=False)\n",
        "\n",
        "    # irrelevant data\n",
        "    preprocessed_comment = []\n",
        "    for item in non_violation_comment:\n",
        "        # preprocessed_comment.append(get_sen_vectors('SO_w2v_200', preprocess(item)))\n",
        "        preprocessed_comment.append(get_sen_vectors('FastText', preprocess(item)))\n",
        "        # preprocessed_comment.append(get_sen_vectors('GloVe_200', preprocess(item)))\n",
        "    Preprocessed_Data = pd.DataFrame(preprocessed_comment)\n",
        "\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\SO_w2v_200_non_violation.csv', index=False)\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_200_non_violation.csv', index=False)\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_100_non_violation.csv', index=False)\n",
        "    Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\FastText_300_non_violation.csv', index=False)\n",
        "    # Preprocessed_Data.to_csv(r'D:\\data\\extracted_features\\GloVe_200_non_violation.csv', index=False)"
      ]
    }
  ]
}