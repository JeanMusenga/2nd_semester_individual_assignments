{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanMusenga/PhD-Thesis_2024_Musenga/blob/main/TextCNN_with_vocab_size.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextCNN model\n",
        "https://chatgpt.com/share/d5dd93d5-d7a7-4488-9bfb-8824d7cffe39\n",
        "\n",
        "The create_text_cnn_model function you provided constructs a TextCNN model for binary text classification. This model uses multiple convolutional layers with different kernel sizes to capture various features from the text data, followed by pooling and concatenation. Here's a detailed explanation of the components:\n",
        "\n",
        "Inputs Layer: Specifies the input shape, which is the maximum length of the sequences.\n",
        "Embedding Layer: Transforms input tokens into dense vectors of fixed size (embedding_dim).\n",
        "Convolutional and Pooling Layers: Three sets of convolutional layers with different kernel sizes (3, 4, and 5) followed by max pooling. These layers help in capturing different n-gram features from the text.\n",
        "Concatenate Layer: Concatenates the outputs of the pooling layers along the specified axis.\n",
        "Flatten Layer: Flattens the concatenated outputs into a single dimension.\n",
        "Dense Layer: A fully connected layer with ReLU activation.\n",
        "Dropout Layer: Helps prevent overfitting by randomly dropping units during training.\n",
        "Output Layer: A single neuron with sigmoid activation for binary classification.\n",
        "Compile Model: Configures the model for training with binary cross-entropy loss, the Adam optimizer, and accuracy as a metric."
      ],
      "metadata": {
        "id": "YTDr5maw-qmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chatgpt.com/share/6b20ab3c-04a2-4b5b-b39b-6531835e3571"
      ],
      "metadata": {
        "id": "obTaIePDvcrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "-4tMggkBn46Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wB3oAsLonvYh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, concatenate, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './saved_file'\n",
        "file_path = ('posts.xlsx')\n",
        "data = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "Wt7TqFW0n43h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data"
      ],
      "metadata": {
        "id": "EBcqgCzKvkmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text data\n",
        "data['Question_body'] = data['Question_body'].str.replace('\\n', ' ').str.replace('<.*?>', '', regex=True)"
      ],
      "metadata": {
        "id": "HEDePz7Hn41B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Question_body'], data['Label'], test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "_e8p6jv0n4yZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "_WzGrfDOn4tp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences\n",
        "max_length = max(len(seq) for seq in X_train_seq)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "nYYfVqOHn4rR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JJhC6kMCvqEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TextCNN model\n",
        "def create_text_cnn_model(vocab_size, embedding_dim, max_length):\n",
        "    inputs = Input(shape=(max_length,))\n",
        "    embedding = Embedding(vocab_size, embedding_dim, input_length=max_length)(inputs)\n",
        "\n",
        "    conv1 = Conv1D(128, 3, activation='relu')(embedding)\n",
        "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(128, 4, activation='relu')(embedding)\n",
        "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    conv3 = Conv1D(128, 5, activation='relu')(embedding)\n",
        "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
        "\n",
        "    concatenated = concatenate([pool1, pool2, pool3], axis=1)\n",
        "    flatten = Flatten()(concatenated)\n",
        "    dense1 = Dense(128, activation='relu')(flatten)\n",
        "    dropout = Dropout(0.5)(dense1)\n",
        "    outputs = Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "bB5IszL4n4mR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100"
      ],
      "metadata": {
        "id": "cHmaVtYH-6Eh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model"
      ],
      "metadata": {
        "id": "AcNok9hCvtxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = create_text_cnn_model(vocab_size, embedding_dim, max_length)"
      ],
      "metadata": {
        "id": "YDFinR7HuM2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d17f163-9999-4c64-beec-711deefc33b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the model summary"
      ],
      "metadata": {
        "id": "QbpqYiKuvzuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model summary\n",
        "text_cnn_model.summary()"
      ],
      "metadata": {
        "id": "AUsxCJ2wuMzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "Q4jMx06gv1me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swqwTC_luMxp",
        "outputId": "32c32768-e927-4ac7-8edd-0dfd8ed5ad55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 124ms/step - accuracy: 0.5194 - loss: 1.6575 - val_accuracy: 0.8957 - val_loss: 0.3414\n",
            "Epoch 2/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 99ms/step - accuracy: 0.8774 - loss: 0.3569 - val_accuracy: 0.9110 - val_loss: 0.2720\n",
            "Epoch 3/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 100ms/step - accuracy: 0.9308 - loss: 0.2298 - val_accuracy: 0.9173 - val_loss: 0.2335\n",
            "Epoch 4/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 96ms/step - accuracy: 0.9649 - loss: 0.1547 - val_accuracy: 0.9125 - val_loss: 0.2559\n",
            "Epoch 5/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 99ms/step - accuracy: 0.9783 - loss: 0.0887 - val_accuracy: 0.9048 - val_loss: 0.3654\n",
            "Epoch 6/10\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9868 - loss: 0.0466 - val_accuracy: 0.9082 - val_loss: 0.4506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "kNyr9vqK_d4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgIERb0Y_VEZ",
        "outputId": "0078ce2a-8715-4b46-aec3-14491cd827d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9141 - loss: 0.2664\n",
            "Test Accuracy: 0.9152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on new data"
      ],
      "metadata": {
        "id": "yLcpOH8yv_Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on new data\n",
        "y_pred_probs = model.predict(X_test_pad)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFOVmAAuMu6",
        "outputId": "d0349b0a-07ff-418f-ca6e-38488d49d93f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display metrics\n",
        "precision_class, recall_class, f1_class, support_class = precision_recall_fscore_support(y_test, y_pred, average=None, labels=[0, 1])\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / conf_matrix.sum()\n",
        "\n",
        "print(f'Class 0 - Precision: {precision_class[0]}, Recall: {recall_class[0]}, Accuracy: {accuracy}, F1-score: {f1_class[0]}, Support: {support_class[0]}')\n",
        "print(f'Class 1 - Precision: {precision_class[1]}, Recall: {recall_class[1]}, Accuracy: {accuracy}, F1-score: {f1_class[1]}, Support: {support_class[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxmNc5E0_yo5",
        "outputId": "c14df8ae-eca6-4e9e-eb5b-481f95e8ec02"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 - Precision: 0.9622363903874448, Recall: 0.866225165562914, Accuracy: 0.9151785714285714, F1-score: 0.9117100371747211, Support: 2265\n",
            "Class 1 - Precision: 0.8758705448586644, Recall: 0.9652370203160271, Accuracy: 0.9151785714285714, F1-score: 0.918384879725086, Support: 2215\n"
          ]
        }
      ]
    }
  ]
}